{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load Whisper Model and save to local Environment"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "## Install whisper api, if cell command does not succeed, use terminal to install library to environment\r\n",
        "\r\n",
        "!pip install git+https://github.com/openai/whisper.git"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting git+https://github.com/openai/whisper.git\n  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-iwq0wc2m\n  Running command git clone -q https://github.com/openai/whisper.git /tmp/pip-req-build-iwq0wc2m\nRequirement already satisfied (use --upgrade to upgrade): whisper==1.0 from git+https://github.com/openai/whisper.git in /anaconda/envs/azureml_py38/lib/python3.8/site-packages\nRequirement already satisfied: numpy in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from whisper==1.0) (1.21.6)\nRequirement already satisfied: torch in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from whisper==1.0) (1.12.0)\nRequirement already satisfied: tqdm in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from whisper==1.0) (4.64.0)\nRequirement already satisfied: more-itertools in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from whisper==1.0) (9.0.0)\nRequirement already satisfied: transformers>=4.19.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from whisper==1.0) (4.24.0)\nRequirement already satisfied: ffmpeg-python==0.2.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from whisper==1.0) (0.2.0)\nRequirement already satisfied: typing-extensions in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from torch->whisper==1.0) (4.3.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from transformers>=4.19.0->whisper==1.0) (0.13.2)\nRequirement already satisfied: requests in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from transformers>=4.19.0->whisper==1.0) (2.28.1)\nRequirement already satisfied: packaging>=20.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from transformers>=4.19.0->whisper==1.0) (21.3)\nRequirement already satisfied: regex!=2019.12.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from transformers>=4.19.0->whisper==1.0) (2022.7.25)\nRequirement already satisfied: pyyaml>=5.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from transformers>=4.19.0->whisper==1.0) (6.0)\nRequirement already satisfied: filelock in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from transformers>=4.19.0->whisper==1.0) (3.7.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from transformers>=4.19.0->whisper==1.0) (0.11.1)\nRequirement already satisfied: future in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ffmpeg-python==0.2.0->whisper==1.0) (0.18.2)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (1.26.9)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2022.6.15)\nRequirement already satisfied: charset-normalizer<3,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (3.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from packaging>=20.0->transformers>=4.19.0->whisper==1.0) (3.0.9)\nBuilding wheels for collected packages: whisper\n  Building wheel for whisper (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n\u001b[?25h  Created wheel for whisper: filename=whisper-1.0-py3-none-any.whl size=1175231 sha256=7601869a031d08bffbee7cb7b6584c40b3801460be170cd9b30730015ed16d8a\n  Stored in directory: /tmp/pip-ephem-wheel-cache-811nr53_/wheels/a7/70/18/b7693c07b1d18b3dafb328f5d0496aa0d41a9c09ef332fd8e6\nSuccessfully built whisper\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669741321553
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#If import fails, run the previous cell in terminal window\n",
        "import whisper\n",
        "\n",
        "#If running on CPU model may fail to load, check the \"./model\" folder for the PyTorch file, if download is successful proceed to the next step.\n",
        "whisper.load_model(\"base.en\", download_root=\"./model\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n100%|███████████████████████████████████████| 139M/139M [00:26<00:00, 5.52MiB/s]\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "Whisper(\n  (encoder): AudioEncoder(\n    (conv1): Conv1d(80, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n    (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n    (blocks): ModuleList(\n      (0): ResidualAttentionBlock(\n        (attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (1): ResidualAttentionBlock(\n        (attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (2): ResidualAttentionBlock(\n        (attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (3): ResidualAttentionBlock(\n        (attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (4): ResidualAttentionBlock(\n        (attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (5): ResidualAttentionBlock(\n        (attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (ln_post): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n  )\n  (decoder): TextDecoder(\n    (token_embedding): Embedding(51864, 512)\n    (blocks): ModuleList(\n      (0): ResidualAttentionBlock(\n        (attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (cross_attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (cross_attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (1): ResidualAttentionBlock(\n        (attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (cross_attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (cross_attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (2): ResidualAttentionBlock(\n        (attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (cross_attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (cross_attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (3): ResidualAttentionBlock(\n        (attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (cross_attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (cross_attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (4): ResidualAttentionBlock(\n        (attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (cross_attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (cross_attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (5): ResidualAttentionBlock(\n        (attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (cross_attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (cross_attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate='none')\n          (2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n  )\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1669742587956
        },
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to Azure Machine Learning Service"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#import required libraries for workspace\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "#import required libraries for environments examples\n",
        "from azure.ai.ml.entities import Environment, BuildContext\n",
        "from azure.ai.ml.entities import Model\n",
        "from azure.ai.ml.constants import ModelType\n",
        "\n",
        "\n",
        "#Enter details of your AzureML workspace\n",
        "subscription_id = 'subscriptionid'\n",
        "resource_group = 'resourcegroup'\n",
        "workspace = 'workspacename'\n",
        "\n",
        "#connect to the workspace\n",
        "ml_client = MLClient(DefaultAzureCredential(), subscription_id, resource_group, workspace)\n",
        "#ml_client = MLClient.from_config(DefaultAzureCredential())"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1669741101315
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save whisper Model to AzureML Model Repository"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file_model = Model(\n",
        "    path=\"model/base.en.pt\",\n",
        "    type=\"custom_model\",\n",
        "    name=\"whisper-base\",\n",
        "    description=\"Model created from local file.\"\n",
        ")\n",
        "ml_client.models.create_or_update(file_model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1668807251798
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create model deployment environment from Docker container definition"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "env_docker_context = Environment(\n",
        "    build=BuildContext(path=\"../environment\"),\n",
        "    name=\"whisper-base-env\",\n",
        "    description=\"Environment created from a Docker context.\",\n",
        ")\n",
        "ml_client.environments.create_or_update(env_docker_context)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1668807405902
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK V2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "c05a5699f0acbfa4d111e4ed5b7e4b2be40df071af7bfa2e01858e66a1d16586"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}